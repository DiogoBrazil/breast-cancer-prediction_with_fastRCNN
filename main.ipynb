{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "\n",
    "        # Carrega todas as imagens e anotações, ordenadas para correspondência\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
    "        self.annotations = list(sorted(os.listdir(os.path.join(root, \"annotations\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Carrega imagem\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Carrega anotações\n",
    "        annot_path = os.path.join(self.root, \"annotations\", self.annotations[idx])\n",
    "        target = self.parse_voc_xml(ET.parse(annot_path).getroot())\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        # Verifica se a chave 'object' existe nas anotações\n",
    "        if 'object' in target['annotation']:\n",
    "            objs = target['annotation']['object']\n",
    "            if not isinstance(objs, list):\n",
    "                objs = [objs]\n",
    "\n",
    "            for obj in objs:\n",
    "                bbox = obj['bndbox']\n",
    "                xmin = float(bbox['xmin'])\n",
    "                ymin = float(bbox['ymin'])\n",
    "                xmax = float(bbox['xmax'])\n",
    "                ymax = float(bbox['ymax'])\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(1)\n",
    "        else:\n",
    "            # Se não houver objetos, criar tensores vazios\n",
    "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "        target_dict = {}\n",
    "        target_dict[\"boxes\"] = boxes\n",
    "        target_dict[\"labels\"] = labels\n",
    "        target_dict[\"image_id\"] = image_id\n",
    "        target_dict[\"area\"] = area\n",
    "        target_dict[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def parse_voc_xml(self, node):\n",
    "        voc_dict = {}\n",
    "        children = list(node)\n",
    "        if children:\n",
    "            def_dict = {}\n",
    "            for dc in map(self.parse_voc_xml, children):\n",
    "                for ind, v in dc.items():\n",
    "                    if ind in def_dict:\n",
    "                        if not isinstance(def_dict[ind], list):\n",
    "                            def_dict[ind] = [def_dict[ind]]\n",
    "                        def_dict[ind].append(v)\n",
    "                    else:\n",
    "                        def_dict[ind] = v\n",
    "            voc_dict[node.tag] = def_dict\n",
    "        else:\n",
    "            voc_dict[node.tag] = node.text\n",
    "        return voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    # Carrega o modelo pré-treinado no COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "\n",
    "    # Obtem o número de características de entrada do classificador\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Substitui o cabeçalho preditor por um novo com o número de classes desejado\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios do conjunto de dados\n",
    "train_dir = 'BD_joing/train'\n",
    "valid_dir = 'BD_joing/valid'\n",
    "test_dir = 'BD_joing/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de classes (incluindo o fundo)\n",
    "num_classes = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os datasets\n",
    "dataset = VOCDataset(train_dir, transforms=get_transform(train=True))\n",
    "dataset_valid = VOCDataset(valid_dir, transforms=get_transform(train=False))\n",
    "dataset_test = VOCDataset(test_dir, transforms=get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=12, collate_fn=collate_fn)\n",
    "data_loader_valid = DataLoader(dataset_valid, batch_size=16, shuffle=False, num_workers=12, collate_fn=collate_fn)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=16, shuffle=False, num_workers=12, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem o modelo\n",
    "model = get_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move modelo para o dispositivo\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros do otimizador\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define otimizador\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marca a taxa de aprendizado\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/100\n",
      "Perda na época 1: 0.2733\n",
      "Época 2/100\n",
      "Perda na época 2: 0.2057\n",
      "Época 3/100\n",
      "Perda na época 3: 0.1816\n",
      "Época 4/100\n",
      "Perda na época 4: 0.1697\n",
      "Época 5/100\n",
      "Perda na época 5: 0.1704\n",
      "Época 6/100\n",
      "Perda na época 6: 0.1665\n",
      "Época 7/100\n",
      "Perda na época 7: 0.1664\n",
      "Época 8/100\n",
      "Perda na época 8: 0.1650\n",
      "Época 9/100\n",
      "Perda na época 9: 0.1638\n",
      "Época 10/100\n",
      "Perda na época 10: 0.1657\n",
      "Época 11/100\n",
      "Perda na época 11: 0.1660\n",
      "Época 12/100\n",
      "Perda na época 12: 0.1630\n",
      "Época 13/100\n",
      "Perda na época 13: 0.1692\n",
      "Época 14/100\n",
      "Perda na época 14: 0.1668\n",
      "Época 15/100\n",
      "Perda na época 15: 0.1659\n",
      "Época 16/100\n",
      "Perda na época 16: 0.1669\n",
      "Época 17/100\n",
      "Perda na época 17: 0.1664\n",
      "Época 18/100\n",
      "Perda na época 18: 0.1660\n",
      "Época 19/100\n",
      "Perda na época 19: 0.1675\n",
      "Época 20/100\n",
      "Perda na época 20: 0.1633\n",
      "Época 21/100\n",
      "Perda na época 21: 0.1656\n",
      "Época 22/100\n",
      "Perda na época 22: 0.1643\n",
      "Época 23/100\n",
      "Perda na época 23: 0.1637\n",
      "Época 24/100\n",
      "Perda na época 24: 0.1675\n",
      "Época 25/100\n",
      "Perda na época 25: 0.1635\n",
      "Época 26/100\n",
      "Perda na época 26: 0.1626\n",
      "Época 27/100\n",
      "Perda na época 27: 0.1684\n",
      "Época 28/100\n",
      "Perda na época 28: 0.1651\n",
      "Época 29/100\n",
      "Perda na época 29: 0.1700\n",
      "Época 30/100\n",
      "Perda na época 30: 0.1638\n",
      "Época 31/100\n",
      "Perda na época 31: 0.1650\n",
      "Época 32/100\n",
      "Perda na época 32: 0.1660\n",
      "Época 33/100\n",
      "Perda na época 33: 0.1619\n",
      "Época 34/100\n",
      "Perda na época 34: 0.1652\n",
      "Época 35/100\n",
      "Perda na época 35: 0.1682\n",
      "Época 36/100\n",
      "Perda na época 36: 0.1621\n",
      "Época 37/100\n",
      "Perda na época 37: 0.1671\n",
      "Época 38/100\n",
      "Perda na época 38: 0.1629\n",
      "Época 39/100\n",
      "Perda na época 39: 0.1645\n",
      "Época 40/100\n",
      "Perda na época 40: 0.1669\n",
      "Época 41/100\n",
      "Perda na época 41: 0.1672\n",
      "Época 42/100\n",
      "Perda na época 42: 0.1639\n",
      "Época 43/100\n",
      "Perda na época 43: 0.1659\n",
      "Época 44/100\n",
      "Perda na época 44: 0.1639\n",
      "Época 45/100\n",
      "Perda na época 45: 0.1668\n",
      "Época 46/100\n",
      "Perda na época 46: 0.1693\n",
      "Época 47/100\n",
      "Perda na época 47: 0.1661\n",
      "Época 48/100\n",
      "Perda na época 48: 0.1669\n",
      "Época 49/100\n",
      "Perda na época 49: 0.1696\n",
      "Época 50/100\n",
      "Perda na época 50: 0.1675\n",
      "Época 51/100\n",
      "Perda na época 51: 0.1654\n",
      "Época 52/100\n",
      "Perda na época 52: 0.1663\n",
      "Época 53/100\n",
      "Perda na época 53: 0.1683\n",
      "Época 54/100\n",
      "Perda na época 54: 0.1662\n",
      "Época 55/100\n",
      "Perda na época 55: 0.1643\n",
      "Época 56/100\n",
      "Perda na época 56: 0.1664\n",
      "Época 57/100\n",
      "Perda na época 57: 0.1659\n",
      "Época 58/100\n",
      "Perda na época 58: 0.1637\n",
      "Época 59/100\n",
      "Perda na época 59: 0.1671\n",
      "Época 60/100\n",
      "Perda na época 60: 0.1665\n",
      "Época 61/100\n",
      "Perda na época 61: 0.1621\n",
      "Época 62/100\n",
      "Perda na época 62: 0.1620\n",
      "Época 63/100\n",
      "Perda na época 63: 0.1657\n",
      "Época 64/100\n",
      "Perda na época 64: 0.1672\n",
      "Época 65/100\n",
      "Perda na época 65: 0.1653\n",
      "Época 66/100\n",
      "Perda na época 66: 0.1641\n",
      "Época 67/100\n",
      "Perda na época 67: 0.1674\n",
      "Época 68/100\n",
      "Perda na época 68: 0.1675\n",
      "Época 69/100\n",
      "Perda na época 69: 0.1644\n",
      "Época 70/100\n",
      "Perda na época 70: 0.1655\n",
      "Época 71/100\n",
      "Perda na época 71: 0.1627\n",
      "Época 72/100\n",
      "Perda na época 72: 0.1635\n",
      "Época 73/100\n",
      "Perda na época 73: 0.1646\n",
      "Época 74/100\n",
      "Perda na época 74: 0.1694\n",
      "Época 75/100\n",
      "Perda na época 75: 0.1635\n",
      "Época 76/100\n",
      "Perda na época 76: 0.1647\n",
      "Época 77/100\n",
      "Perda na época 77: 0.1647\n",
      "Época 78/100\n",
      "Perda na época 78: 0.1641\n",
      "Época 79/100\n",
      "Perda na época 79: 0.1694\n",
      "Época 80/100\n",
      "Perda na época 80: 0.1653\n",
      "Época 81/100\n",
      "Perda na época 81: 0.1678\n",
      "Época 82/100\n",
      "Perda na época 82: 0.1663\n",
      "Época 83/100\n",
      "Perda na época 83: 0.1660\n",
      "Época 84/100\n",
      "Perda na época 84: 0.1670\n",
      "Época 85/100\n",
      "Perda na época 85: 0.1677\n",
      "Época 86/100\n",
      "Perda na época 86: 0.1653\n",
      "Época 87/100\n",
      "Perda na época 87: 0.1663\n",
      "Época 88/100\n",
      "Perda na época 88: 0.1661\n",
      "Época 89/100\n",
      "Perda na época 89: 0.1659\n",
      "Época 90/100\n",
      "Perda na época 90: 0.1690\n",
      "Época 91/100\n",
      "Perda na época 91: 0.1680\n",
      "Época 92/100\n",
      "Perda na época 92: 0.1658\n",
      "Época 93/100\n",
      "Perda na época 93: 0.1676\n",
      "Época 94/100\n",
      "Perda na época 94: 0.1650\n",
      "Época 95/100\n",
      "Perda na época 95: 0.1676\n",
      "Época 96/100\n",
      "Perda na época 96: 0.1677\n",
      "Época 97/100\n",
      "Perda na época 97: 0.1644\n",
      "Época 98/100\n",
      "Perda na época 98: 0.1672\n",
      "Época 99/100\n",
      "Perda na época 99: 0.1647\n",
      "Época 100/100\n",
      "Perda na época 100: 0.1645\n",
      "Treinamento concluído.\n"
     ]
    }
   ],
   "source": [
    "# Número de épocas\n",
    "num_epochs = 100\n",
    "\n",
    "# Treinamento\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Época {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    i = 0\n",
    "    epoch_loss = 0\n",
    "    # Loop de treinamento\n",
    "    for images, targets in data_loader:\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Média da perda na época\n",
    "    epoch_loss /= len(data_loader)\n",
    "    print(f\"Perda na época {epoch+1}: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Atualiza a taxa de aprendizado\n",
    "    lr_scheduler.step()\n",
    "\n",
    "print(\"Treinamento concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo como 'faster_rcnn_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'faster_rcnn_model.pth')\n",
    "print(\"Modelo salvo como 'faster_rcnn_model.pth'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_rcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
